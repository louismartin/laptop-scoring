{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laptop specifications scrapper\n",
    "Scrap comparez-malin.com for laptop specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_and_reload_df(func):\n",
    "    \"\"\"\n",
    "    Decorator that saves the dataframe computed by the function\n",
    "    and loads it if it was already saved\n",
    "    \"\"\"\n",
    "    def func_wrapper(*args, overwrite=False, **kwargs):\n",
    "        csv_path = \"data/{}.csv\".format(func.__name__)\n",
    "        if not os.path.exists(csv_path) or overwrite:\n",
    "            df = func(*args, **kwargs)\n",
    "            df.to_csv(csv_path)\n",
    "        else:\n",
    "            print(\"Reading dataframe from {}\".format(csv_path))\n",
    "            df = pd.read_csv(csv_path, index_col=0)\n",
    "        return df\n",
    "    return func_wrapper\n",
    "\n",
    "\n",
    "def get_specs(url):\n",
    "    \"\"\"Return specs as a dictionary\"\"\"\n",
    "    html_doc = urlopen(url)\n",
    "    html_doc = html_doc.read()\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "    soup = soup.find(\"div\", {\"id\": \"specs\"})\n",
    "    specs = {}\n",
    "    for spec in soup.find_all(\"tr\"):\n",
    "        key, value = extract_spec(spec)\n",
    "        if key:\n",
    "            specs[key] = value\n",
    "    \n",
    "    return specs\n",
    "\n",
    "\n",
    "def extract_spec(spec):\n",
    "    key = spec.find(\"th\", {\"scope\": \"row\"})\n",
    "    if key:\n",
    "        key = key.text\n",
    "        key = key.replace(\"\\n\", \" \").strip()\n",
    "        value = spec.find(\"td\").text\n",
    "        value = value.replace(\"\\n\", \" \").strip()\n",
    "        value = value.replace(u'\\xa0', u' ')\n",
    "    else:\n",
    "        return None, None\n",
    "    return key, value\n",
    "\n",
    "\n",
    "def get_laptop_urls_in_page(page_url):\n",
    "    root_url = \"http://www.comparez-malin.fr/informatique/pc-portable/\"\n",
    "    html_doc = urlopen(page_url).read()\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "    laptop_blocks = soup.find_all(\"div\", {\"class\": \"product\"})\n",
    "    specs_urls = {}\n",
    "    for block in laptop_blocks:\n",
    "        try:\n",
    "            key = block[\"id\"]\n",
    "            url = block.find(\"a\", {\"class\": \"white\"})[\"href\"]\n",
    "            if \"tablette\" not in url:\n",
    "                url = urljoin(root_url, url.split('/')[-1])\n",
    "                specs_urls[key] = url\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return specs_urls\n",
    "\n",
    "\n",
    "def add_columns(df, columns):\n",
    "    \"\"\"Add columns to a dataframe\"\"\"\n",
    "    # Remove columns that are already there\n",
    "    columns = set(columns) - set(df.columns)\n",
    "    df_columns = pd.DataFrame(columns=columns)\n",
    "    df = df.join(df_columns, how='outer')\n",
    "    return df\n",
    "\n",
    "@save_and_reload_df\n",
    "def get_laptops_urls():\n",
    "    \"\"\"Get links to each laptop page in a dataframe\"\"\"\n",
    "    root_url = \"http://www.comparez-malin.fr/informatique/pc-portable/{}\"\n",
    "    n = 265\n",
    "    specs_urls = {}\n",
    "    for i in tqdm(range(n)):\n",
    "        page_url = root_url.format(i+1)\n",
    "        specs_urls.update(get_laptop_urls_in_page(page_url))\n",
    "\n",
    "    # Convert urls to dataframe\n",
    "    s = pd.Series(specs_urls, name='url')\n",
    "    df = s.to_frame()\n",
    "    df.to_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "@save_and_reload_df\n",
    "def get_all_laptops_specs(df_laptops_urls, overwrite=False):\n",
    "    \"\"\"Get specs for all laptops urls\"\"\"\n",
    "    df = df_laptops_urls\n",
    "    # Initialize columns\n",
    "    url = df.iloc[0][\"url\"]\n",
    "    specs = get_specs(url)\n",
    "    columns = set(specs.keys())\n",
    "    df = add_columns(df, columns)\n",
    "    columns = set(df.columns)\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if row.isnull().values[1:].all():\n",
    "            url = row[\"url\"]\n",
    "            specs = get_specs(url)\n",
    "            if len(specs) == 0:\n",
    "                print(url)\n",
    "                pass\n",
    "            specs[\"url\"] = url\n",
    "            new_cols = set(specs.keys())\n",
    "            if (new_cols != columns):\n",
    "                df = add_columns(df, new_cols - columns)\n",
    "                columns = set(df.columns)\n",
    "            df.loc[index] = specs\n",
    "    df.to_csv('data/all_specs.csv')\n",
    "    return df\n",
    "\n",
    "def get_cpu_benchmark(cpu_name):\n",
    "    root_url = \"http://www.cpubenchmark.net/cpu.php?cpu={}\"\n",
    "    try:\n",
    "        url = root_url.format(cpu_name.replace(\" \", \"+\"))\n",
    "        html_doc = urlopen(url).read()\n",
    "        soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "        # Square with perf and single thread rating\n",
    "        soup = soup.find(\"td\", {\"style\": \"text-align: center\"})\n",
    "        benchmark = int(soup.find(\"span\").text)\n",
    "    except HTTPError:\n",
    "        benchmark = None\n",
    "    return benchmark\n",
    "\n",
    "@save_and_reload_df\n",
    "def get_cpu_dataframe():\n",
    "    cpus = df[\"processeur\"].unique()\n",
    "    df_cpu = pd.DataFrame(cpus, columns=[\"processeur\"])\n",
    "    for index, row in tqdm(df_cpu.iterrows(), total=df_cpu.shape[0]):\n",
    "        benchmark = get_cpu_benchmark(row[\"processeur\"])\n",
    "        df_cpu.loc[index, \"cpu_benchmark\"] = benchmark\n",
    "    return df_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_get_specs():\n",
    "    url = \"http://www.comparez-malin.fr/informatique/pc-portable/asus-zenbook-3-ux390ua-gs039r.html\"\n",
    "    specs = get_specs(url)\n",
    "    retrieved_specs_keys = list(specs.keys())\n",
    "    filename = \"data/test_get_specs_keys.txt\"\n",
    "    with open(filename, \"r\") as fp:\n",
    "        true_specs_keys = fp.readlines()\n",
    "    true_specs_keys = [key.replace(\"\\n\", \" \").strip() for key in true_specs_keys]\n",
    "    not_retrieved = set(true_specs_keys) - set(retrieved_specs_keys)\n",
    "    assert len(not_retrieved) == 0, \"Not retrieved: {}\".format(not_retrieved)\n",
    "    not_asked = set(retrieved_specs_keys) - set(true_specs_keys)\n",
    "    assert len(not_asked) == 0, \"Not asked: {}\".format(not_asked)\n",
    "test_get_specs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links to each laptop page in a  dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_laptops_urls = get_laptops_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specs for all laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_laptops_urls = df_laptops_urls.sample(n=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = get_all_laptops_specs(df_laptops_urls, overwrite=False)\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\").str.replace(\".\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get CPU benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cpu = get_cpu_dataframe()\n",
    "df = df.reset_index().merge(df_cpu, on=\"processeur\", how=\"left\").set_index(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_prix_public(price):\n",
    "    price = price.strip(\"€\")\n",
    "    price = price.replace(\" \", \"\")\n",
    "    price = price.replace(\",\", \".\")\n",
    "    price = float(price)\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_methods = {\n",
    "    \"prix_public\": process_prix_public\n",
    "}\n",
    "\n",
    "for col, method in col_methods.items():\n",
    "    df[col] = df[col].apply(lambda x: method(x))\n",
    "    \n",
    "df[[\"cores\", \"min_freq\", \"max_freq\"]] = df[\"fréquence\"].str.split(expand=True)[[0,2,4]].astype(float)\n",
    "df[\"pdt_max\"] = df[\"pdt_max\"].str.split(expand=True)[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_disque_dur(string):\n",
    "    string = string.replace(\"(\", \"\").replace(\")\", \"\").replace(u'\\xa0', u' ')\n",
    "    sshd = \"cache SSD\" in string\n",
    "    string = string.replace(\"cache SSD\", \"\")\n",
    "    hdd_size = 0\n",
    "    hdd_speed = 0\n",
    "    if \"tr/min\" in string:\n",
    "        hdd_string, string = string.split(\"tr/min\")\n",
    "        splitted = hdd_string.split()\n",
    "        hdd_size = int(splitted[0])\n",
    "        hdd_speed = int(splitted[-1])\n",
    "    ssd_size = 0\n",
    "    if \"Go SSD\" in string:\n",
    "        ssd_size = int(string.split(\"Go SSD\")[0].split()[-1])\n",
    "    return hdd_size, hdd_speed, sshd, ssd_size\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    hdd_size, hdd_speed, sshd, ssd_size = process_disque_dur(row[\"disque_dur\"])\n",
    "    df.loc[index, \"hdd_size\"] = hdd_size\n",
    "    df.loc[index, \"hdd_speed\"] = hdd_speed\n",
    "    df.loc[index, \"sshd\"] = sshd\n",
    "    df.loc[index, \"ssd_size\"] = ssd_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring_methods = {\n",
    "    \"cpu_benchmark\": lambda x: x/4000 * 0.8,\n",
    "    \"min_freq\": lambda x: x/2.5 * 0.2,\n",
    "    \"max_freq\": lambda x: x/3.3 * 0.4,\n",
    "    \"pdt_max\": lambda x: x/38 * -0.25,\n",
    "    \"hdd_speed\": lambda x: (x==7200) * 0.2,\n",
    "    \"sshd\": lambda x: x * 0.4,\n",
    "    \"ssd_size\": lambda x: ((x>0) + np.sqrt(x/128)) * 0.6,\n",
    "    \"prix_public\": lambda x: (x/800) ** 0.6\n",
    "}\n",
    "\n",
    "df_score = pd.DataFrame(index=df.index, columns=[\"score\"])\n",
    "# Generic methods that take one column as input\n",
    "# and output its associated score\n",
    "for col, method in tqdm(scoring_methods.items()):\n",
    "    df_score[col] = df[col].apply(method)\n",
    "    \n",
    "# Compute total score\n",
    "df_score[\"score\"] = df_score.drop([\"score\", \"prix_public\"], axis=1).sum(axis=1)\n",
    "df_score[\"score\"] /= df_score[\"prix_public\"]\n",
    "df_score[\"score\"] /= df_score[\"score\"].max()\n",
    "df[\"score\"] = df_score[\"score\"]\n",
    "df = df.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#qgrid.set_defaults(grid_options={'forceFitColumns': False})#, 'defaultColumnWidth': 200})\n",
    "cols_to_show = \"url score cpu_benchmark min_freq max_freq pdt_max hdd_speed sshd ssd_size prix_public\".split()\n",
    "qgrid.show_grid(df[cols_to_show])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "7333ab1d6441411babea6ce966f1c854": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
