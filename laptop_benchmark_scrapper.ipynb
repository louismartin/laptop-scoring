{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laptop specifications scrapper\n",
    "Scrap comparez-malin.com for laptop specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_specs(url):\n",
    "    \"\"\"Return specs as a dictionary\"\"\"\n",
    "    html_doc = urlopen(url)\n",
    "    html_doc = html_doc.read()\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "    soup = soup.find(\"div\", {\"id\": \"specs\"})\n",
    "    specs = {}\n",
    "    for spec in soup.find_all(\"tr\"):\n",
    "        key, value = extract_spec_(spec)\n",
    "        if key:\n",
    "            specs[key] = value\n",
    "    \n",
    "    return specs\n",
    "\n",
    "\n",
    "def extract_spec_(spec):\n",
    "    key = spec.find(\"th\", {\"scope\": \"row\"})\n",
    "    if key:\n",
    "        key = key.text\n",
    "        value = spec.find(\"td\").text.replace('\\n', '')\n",
    "    else:\n",
    "        return None, None\n",
    "    return key, value\n",
    "\n",
    "\n",
    "def extract_spec(spec):\n",
    "    key_val = spec.find_all(\"td\")\n",
    "    if len(key_val) == 2:\n",
    "        key = key_val[0].text\n",
    "        value = key_val[1].text\n",
    "        value = value.replace(\"\\n\", \"\")\n",
    "        value = value.replace(\"\\xa0\", \"  \")\n",
    "    else:\n",
    "        key = None\n",
    "        value = None\n",
    "    return key, value\n",
    "\n",
    "\n",
    "def get_laptop_urls_in_page(page_url):\n",
    "    root_url = \"http://www.comparez-malin.fr/informatique/pc-portable/\"\n",
    "    html_doc = urlopen(page_url).read()\n",
    "    soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "    laptop_blocks = soup.find_all(\"div\", {\"class\": \"product\"})\n",
    "    specs_urls = {}\n",
    "    for block in laptop_blocks:\n",
    "        try:\n",
    "            key = block[\"id\"]\n",
    "            url = block.find(\"a\", {\"class\": \"white\"})[\"href\"]\n",
    "            if \"tablette\" not in url:\n",
    "                url = urljoin(root_url, url.split('/')[-1])\n",
    "                specs_urls[key] = url\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return specs_urls\n",
    "\n",
    "\n",
    "def add_columns(df, columns):\n",
    "    \"\"\"Add columns to a dataframe\"\"\"\n",
    "    # Remove columns that are already there\n",
    "    columns = set(columns) - set(df.columns)\n",
    "    df_columns = pd.DataFrame(columns=columns)\n",
    "    df = df.join(df_columns, how='outer')\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_laptops_urls(overwrite=False):\n",
    "    \"\"\"Get links to each laptop page in a dataframe\"\"\"\n",
    "    csv_path = 'data/specs_urls.csv'\n",
    "    if not os.path.exists(csv_path) or overwrite:\n",
    "        root_url = \"http://www.comparez-malin.fr/informatique/pc-portable/{}\"\n",
    "        n = 265\n",
    "        specs_urls = {}\n",
    "        for i in tqdm(range(n)):\n",
    "            page_url = root_url.format(i+1)\n",
    "            specs_urls.update(get_laptop_urls_in_page(page_url))\n",
    "\n",
    "        # Convert urls to dataframe\n",
    "        s = pd.Series(specs_urls, name='url')\n",
    "        df = s.to_frame()\n",
    "        df.to_csv(csv_path)\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_laptops_specs(df_laptops_urls, overwrite=False):\n",
    "    \"\"\"Get specs for all laptops urls\"\"\"\n",
    "    df = df_laptops_urls\n",
    "    csv_path = 'data/all_specs.csv'\n",
    "    if not os.path.exists(csv_path) or overwrite:\n",
    "        # Initialize columns\n",
    "        url = df.iloc[0][\"url\"]\n",
    "        specs = get_specs(url)\n",
    "        columns = set(specs.keys())\n",
    "        df = add_columns(df, columns)\n",
    "        columns = set(df.columns)\n",
    "\n",
    "        for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            if row.isnull().values[1:].all():\n",
    "                url = row[\"url\"]\n",
    "                specs = get_specs(url)\n",
    "                if len(specs) == 0:\n",
    "                    print(url)\n",
    "                    pass\n",
    "                specs[\"url\"] = url\n",
    "                new_cols = set(specs.keys())\n",
    "                if (new_cols != columns):\n",
    "                    df = add_columns(df, new_cols - columns)\n",
    "                    columns = set(df.columns)\n",
    "                df.loc[index] = specs\n",
    "        #df.to_csv('data/all_specs.csv')\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_get_specs():\n",
    "    url = \"http://www.comparez-malin.fr/informatique/pc-portable/asus-zenbook-3-ux390ua-gs039r.html\"\n",
    "    specs = get_specs(url)\n",
    "    retrieved_specs_keys = list(specs.keys())\n",
    "    filename = \"data/test_get_specs_keys.txt\"\n",
    "    with open(filename, \"r\") as fp:\n",
    "        true_specs_keys = fp.readlines()\n",
    "    true_specs_keys = [key.replace(\"\\n\", \"\") for key in true_specs_keys]\n",
    "    not_retrieved = set(true_specs_keys) - set(retrieved_specs_keys)\n",
    "    assert len(not_retrieved) == 0, \"Not retrieved: {}\".format(not_retrieved)\n",
    "    not_asked = set(retrieved_specs_keys) - set(true_specs_keys)\n",
    "    assert len(not_asked) == 0, \"Not asked: {}\".format(not_asked)\n",
    "test_get_specs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get links to each laptop page in a  dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_laptops_urls = get_laptops_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specs for all laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = get_all_laptops_specs(df_laptops_urls, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
